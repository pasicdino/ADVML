{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    #n represents number of inputs\n",
    "    def __init__(self, n):\n",
    "        #randomly assign weights and bias terms as values between -1 and 1\n",
    "        self.input_weights = np.random.uniform(-1, 1, n)\n",
    "        self.bias = np.random.uniform(-1, 1)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        weights_str = ', '.join(f'{w:.2f}' for w in self.input_weights) if self.input_weights is not None else \"No input weights\"\n",
    "        return f\"Input weights: [{weights_str}] | Bias term: {self.bias:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "        #n represents number of neurons in layer\n",
    "        def __init__(self, n, inputs_per_neuron):\n",
    "            #create list of neurons\n",
    "            self.neurons = [Neuron(inputs_per_neuron) for _ in range(n)]\n",
    "\n",
    "        def __str__(self):\n",
    "            layer_info = f'Layer ({len(self.neurons)}):\\n'\n",
    "            for i, neuron in enumerate(self.neurons, start=1):\n",
    "                layer_info += f' Neuron {i}:\\n    {neuron}\\n'\n",
    "            return layer_info\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    #input of layers: list where each item represents a layer and the value represents the size of the layer\n",
    "    def __init__(self,layer_sizes):\n",
    "        #init first layer manually as it has no input weights\n",
    "        self.layers = []\n",
    "        self.layers.append(Layer(layer_sizes[0], 0))\n",
    "        #init the rest in loop with the num of inputs being equal to the num of neurons in the previous layer (full network)\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.layers.append(Layer(layer_sizes[i], layer_sizes[i-1]))\n",
    "\n",
    "    def __str__(self):\n",
    "        network_str = ''\n",
    "        for i, layer in enumerate(self.layers, start=1):\n",
    "            network_str += f'Layer {i}:\\n{layer}\\n'\n",
    "        return network_str.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:\n",
      "Layer (8):\n",
      " Neuron 1:\n",
      "    Input weights: [] | Bias term: -0.65\n",
      " Neuron 2:\n",
      "    Input weights: [] | Bias term: 0.68\n",
      " Neuron 3:\n",
      "    Input weights: [] | Bias term: 0.08\n",
      " Neuron 4:\n",
      "    Input weights: [] | Bias term: 0.37\n",
      " Neuron 5:\n",
      "    Input weights: [] | Bias term: -0.71\n",
      " Neuron 6:\n",
      "    Input weights: [] | Bias term: 0.45\n",
      " Neuron 7:\n",
      "    Input weights: [] | Bias term: 0.97\n",
      " Neuron 8:\n",
      "    Input weights: [] | Bias term: 0.93\n",
      "\n",
      "Layer 2:\n",
      "Layer (3):\n",
      " Neuron 1:\n",
      "    Input weights: [0.09, 0.08, -0.55, 0.37, -0.85, -0.89, -0.46, -0.11] | Bias term: -0.24\n",
      " Neuron 2:\n",
      "    Input weights: [0.09, -0.25, 0.10, 0.86, -0.78, 0.24, 0.94, 0.97] | Bias term: -0.69\n",
      " Neuron 3:\n",
      "    Input weights: [-0.84, -0.41, 0.79, 0.84, 0.96, 0.87, 0.05, -0.26] | Bias term: 0.72\n",
      "\n",
      "Layer 3:\n",
      "Layer (8):\n",
      " Neuron 1:\n",
      "    Input weights: [-0.06, -1.00, -0.80] | Bias term: 0.53\n",
      " Neuron 2:\n",
      "    Input weights: [0.04, -0.71, 0.51] | Bias term: -0.75\n",
      " Neuron 3:\n",
      "    Input weights: [0.70, 0.13, -0.65] | Bias term: -0.93\n",
      " Neuron 4:\n",
      "    Input weights: [0.03, -0.05, -0.38] | Bias term: -0.82\n",
      " Neuron 5:\n",
      "    Input weights: [0.89, -0.75, -0.29] | Bias term: 0.51\n",
      " Neuron 6:\n",
      "    Input weights: [0.98, 0.11, 0.31] | Bias term: -0.13\n",
      " Neuron 7:\n",
      "    Input weights: [-0.18, -0.12, -0.29] | Bias term: 0.81\n",
      " Neuron 8:\n",
      "    Input weights: [0.07, -0.99, 0.75] | Bias term: 0.72\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([8,3,8])\n",
    "print(nn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
