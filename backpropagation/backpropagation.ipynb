{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    #n represents number of inputs\n",
    "    def __init__(self, n):\n",
    "        #randomly assign weights and bias terms as values between -1 and 1\n",
    "        self.input_weights = np.random.uniform(-1, 1, n)\n",
    "        self.bias = np.random.uniform(-1, 1)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        weights_str = ', '.join(f'{w:.2f}' for w in self.input_weights) if self.input_weights is not None else \"No input weights\"\n",
    "        return f\"Input weights: [{weights_str}] | Bias term: {self.bias:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Layer:\n",
    "        #n represents number of neurons in layer\n",
    "        def __init__(self, n, inputs_per_neuron):\n",
    "            #create list of neurons\n",
    "            self.neurons = [Neuron(inputs_per_neuron) for _ in range(n)]\n",
    "\n",
    "        #computing outputs of a layer based on previous layer's outputs (this layer's inputs)\n",
    "        def compute_outputs(self, inputs):\n",
    "            #store outputs here\n",
    "            outputs = []\n",
    "\n",
    "            #for all neurons in the layer\n",
    "            for neuron in self.neurons:\n",
    "                #calculate the weighted sum of the neurons weights and the inputs and add the bias\n",
    "                weighted_sum = np.dot(neuron.input_weights, inputs) + neuron.bias\n",
    "\n",
    "                #put it through the sigmoid function\n",
    "                neuron_output = sigmoid(weighted_sum)\n",
    "\n",
    "                #append to layer outputs\n",
    "                outputs.append(neuron_output)\n",
    "            return outputs\n",
    "\n",
    "        def __str__(self):\n",
    "            layer_info = f'Layer ({len(self.neurons)}):\\n'\n",
    "            for i, neuron in enumerate(self.neurons, start=1):\n",
    "                layer_info += f' Neuron {i}:\\n    {neuron}\\n'\n",
    "            return layer_info\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def compute_loss(output, desired_output):\n",
    "        loss = 0\n",
    "        for i in range(len(output)):\n",
    "            loss += (output[i]-desired_output[i])**2\n",
    "        return loss\n",
    "\n",
    "class NeuralNetwork:\n",
    "    #input of layers: list where each item represents a layer and the value represents the size of the layer\n",
    "    def __init__(self,layer_sizes):\n",
    "        #init first layer manually as it has no input weights\n",
    "        self.layers = []\n",
    "        self.layers.append(Layer(layer_sizes[0], 0))\n",
    "        #init the rest in loop with the num of inputs being equal to the num of neurons in the previous layer (full network)\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.layers.append(Layer(layer_sizes[i], layer_sizes[i-1]))\n",
    "\n",
    "    def feedforward(self, input_data):\n",
    "        #make sure the input data is the correct size\n",
    "        assert len(self.layers[0].neurons) == len(input_data)\n",
    "\n",
    "        #set the outputs of the first layer equal to the input data\n",
    "        self.layers[0].outputs = input_data\n",
    "\n",
    "        #for all next layers, compute the outputs, using the previous' layer outputs as inputs\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i].outputs = self.layers[i].compute_outputs(self.layers[i-1].outputs)\n",
    "\n",
    "        #return the last layer's outputs\n",
    "        return self.layers[-1].outputs\n",
    "\n",
    "    def __str__(self):\n",
    "        network_str = ''\n",
    "        for i, layer in enumerate(self.layers, start=1):\n",
    "            network_str += f'Layer {i}:\\n{layer}\\n'\n",
    "        return network_str.strip()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7200955100347002\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([8,3,8])\n",
    "input = [1,0,0,0,0,0,0,0]\n",
    "desired_output = input\n",
    "output = nn.feedforward(input)\n",
    "loss = compute_loss(output, desired_output)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
