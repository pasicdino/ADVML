{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def SSR(output, desired_output):\n",
    "    #calculate loss but vectorized\n",
    "    loss = np.sum((desired_output - output) ** 2)\n",
    "    return loss\n",
    "\n",
    "def dSSR(output, desired_output):\n",
    "    #derivative of loss\n",
    "    gradient = -2 * (desired_output - output)\n",
    "    return gradient\n",
    "\n",
    "def calculate_step_sizes(values, alpha=0.1):\n",
    "    #basically the gradient descent part\n",
    "    #the layer_derivative are just the values\n",
    "    layer_derivatives = np.array(values)\n",
    "    step_sizes = alpha * layer_derivatives\n",
    "\n",
    "    return step_sizes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    #keep everything in np arrays as that allows for list operations\n",
    "    def __init__(self, n):\n",
    "        self.input_weights = np.random.uniform(-1, 1, n)\n",
    "        self.bias = np.random.uniform(-1, 1)\n",
    "\n",
    "    def __str__(self):\n",
    "        weights_str = ', '.join(f'{w:.2f}' for w in self.input_weights)\n",
    "        return f\"Input weights: [{weights_str}] | Bias term: {self.bias:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    #again more list operations\n",
    "    def __init__(self, num_neurons, inputs_per_neuron):\n",
    "        self.weights = np.random.uniform(-1, 1, (num_neurons, inputs_per_neuron))\n",
    "        self.biases = np.random.uniform(-1, 1, num_neurons)\n",
    "\n",
    "    #this calculates the output of the input & weights and puts it through sigmoid\n",
    "    def compute_outputs(self, inputs):\n",
    "        weighted_sum = np.dot(inputs, self.weights.T) + self.biases\n",
    "        return sigmoid(weighted_sum)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join('Neuron {}: {}'.format(i + 1, neuron)\n",
    "                         for i, neuron in enumerate(self.weights))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    #NN consists of layers\n",
    "    #First layer does not have inputs. all others do\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.layers = []\n",
    "        input_size = layer_sizes[0]\n",
    "        for output_size in layer_sizes[1:]:\n",
    "            self.layers.append(Layer(output_size, input_size))\n",
    "            input_size = output_size\n",
    "\n",
    "    #calculate output from input, feeding it forward\n",
    "    def feedforward(self, input_data):\n",
    "        activations = input_data\n",
    "        for layer in self.layers:\n",
    "            activations = layer.compute_outputs(activations)\n",
    "        return activations\n",
    "\n",
    "    #Right now this only does the last layer as that derivative is pretty easy\n",
    "    #The first and second layer are more difficult as they have both weights and biases\n",
    "    #And the chain rule is just more complicated\n",
    "    def train(self, input_data, desired_output, epochs, learning_rate=0.05):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.feedforward(input_data)\n",
    "\n",
    "            loss = SSR(output, desired_output)\n",
    "            print(\"Loss: {loss}\")\n",
    "\n",
    "            derivatives = dSSR(output, desired_output)\n",
    "\n",
    "            step_sizes = calculate_step_sizes(derivatives, alpha=learning_rate)\n",
    "\n",
    "            self.layers[-1].biases -= step_sizes\n",
    "\n",
    "    def __str__(self):\n",
    "        return '\\n'.join(f'Layer {i + 1}:\\n{layer}' for i, layer in enumerate(self.layers))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([8,3,8])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n",
      "Loss: {loss}\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    #random input\n",
    "    input = np.zeros(8)\n",
    "    random_index = np.random.randint(8)\n",
    "    input[random_index] = 1\n",
    "    desired_output = input\n",
    "\n",
    "    nn.train(input, desired_output, 1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nn.feedforward([0,0,0,0,1,0,0,0])).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
